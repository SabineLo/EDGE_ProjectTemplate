#Import the libraries
#What these are for is to add what is needed it allows us to use specific 
# commands that previously were unable to add



#Now what questions do you have?
#Research wise why did you choose this website from the data scraped what do you want to figure out
#Example: Fastest time to cross the border, best wait time for a ride. All this stuff!
"""Before you choose what website figure out what you want to find"""

#This is where you choose which website you want to access you will input the link here


#Create a function
#Purpose: inspect the elements in the website you want to get the data from and see the HTML tags
def data_inspection():
    print('Yes')


#Create a function
#Purpose: Store the data you have now scraped into a csv file, more organized easier to read
def data_sorted():
    print('csv!')



#Now answer the questions with the data you have organized idk if to go to a diff file I think I will